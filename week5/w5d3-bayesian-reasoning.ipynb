{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference\n",
    "\n",
    "Let's say you have three coins. Two are normal \"fair\" coins, and one is weighted so that it _always_ flips heads. You pick a coin at random and flip it three times.\n",
    "\n",
    "If you get heads every time you flip that coin, _what is the chance it's the weighted coin?_\n",
    "\n",
    "If you think there's a greater than 1/3 chance of it being the weighted coin, you're thinking Bayesian.\n",
    "\n",
    "**Bayesian Inference** is basically updating your beliefs after considering new evidence.\n",
    "\n",
    "We can update our confidence as we get more evidence, though rrarely are we absolutely certain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Bayesian is different\n",
    "\n",
    "Bayesian inference does differ from most traditional statistical inference models in that it _preserves uncertainy_. The Bayesian worldview interprets probability as a measure of _believability_ of an event occurring.\n",
    "\n",
    "Assigning a belief of 0 indicates that an individual has no confidence the event will occur. Assigning a belief of 1 indicates that an individual is absolutely certain the event will occur.\n",
    "\n",
    "Belief in Bayesian inference refers to an **individual's** measurement. This leaves room for conflicting beliefs. Different individuals have access to different evidence, and therefore can update their beliefs differently. Access to different evidence doesn't imply an individual is wrong, especially if there is room for uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider these examples:\n",
    "\n",
    "* I flip a coin, we both guess the result. If the coin is fair, we would probably both agree that that the probability of flipping heads is 1/2. Now let's say before we make \"guesses\" about the result, I take a peek at the coin. I can then update my beliefs based on new evidence and make a certain \"guess\" about the state of the coin. My knowledge of the outcome hasn't changed the result, but it's changed my belief.\n",
    "* Your code either has a bug in it or it doesn't. We don't know for certain which is true, but if we run a lot of tests on it we can update our beliefs and be more certain that it's bug-free, or we can see that a test fails and that there is likely to be a bug.\n",
    "* A medical patient is exhibiting symptoms _x_, _y_, and _z_. There are many diseases that could have all three of these symptoms. One doctor believes it is disease A, another believes it is disease B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beliefs are things that we as humans deal with in everyday life all the time. Our interactions are constantly based upon our beliefs.\n",
    "\n",
    "Our belief about an event $A$ is denoted as $P(A)$. This is called the _Prior Probability_, as it's the probability before considering new evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayesian individual updates their beliefs after seeing evidence. Even if the evidence is counter to what the Bayesian originally believed, they can't ignore the evidence - they must update their beliefs. An updated belief is denoted as $P(A|X)$, called the _Posterior Probability_, as contrasted to the _Prior Probability_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we chose a coin at random, we believed we had a 1/3 probability of it being the weighted coin. $P(A) = \\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we flip the coin, and we saw a heads three times, we have new evidence and can calculate $P(A|X)$.\n",
    "\n",
    "Let's start with the situation of one heads.\n",
    "\n",
    "A is the prior probability (1/3), $X$ is our new evidence (and the probability of it happening)\n",
    "\n",
    "Bayes' Theorem:\n",
    "\n",
    "$P(A|X) = \\frac{ P(X | A) P(A) } {P(X)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of A given the evidence X is equal to the probability of X given A multiplied by the probability of A, all divided by the probability of X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(A) = 1/3\n",
    "\n",
    "To get the probability of X, we need some calculations. The likelihood of flipping a normal coin and getting heads is 1/2. The likelihood of flipping a weighted coin and getting heads is 1. So to calculate the likelihood of flipping a random coin and getting heads is the average of the probabilities of all our possibilities:\n",
    "\n",
    "$ \\frac { \\frac{1}{2} + \\frac{1}{2} + 1}{3} = \\frac{2}{3} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of X given A is a little weird, but written out, it's the probability of getting heads (X) given that we know we have the weighted coin (A). If we have the weighted coin, our probability of heads is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new probability is $ \\frac {\\frac{1}{3}} {\\frac{2}{3}} = $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's the point?\n",
    "\n",
    "Bayesian inference can help with a lot of things in machine learning. Every time we get new evidence we can update our beliefs about something.\n",
    "\n",
    "Classic examples of Bayesian inference are spam filters.\n",
    "\n",
    "Let's say we know that of our previous emails received, 50% of them have been spam. We get an email with the word \"loan\" in it. We know that 1.5% of our spam emails have the word \"loan\" in them. We also know that only 1% of total emails we get have the word loan in them. So what's the chance this new email is spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A - email is spam\n",
    "# X - email has \"loan\" in it\n",
    "\n",
    "spam_chance = 0.5 # P(A)\n",
    "loan_chance = 0.01 # P(X)\n",
    "loan_in_spam_chance = 0.015 # P(X | A)\n",
    "\n",
    "updated_chance = (loan_in_spam_chance * spam_chance) / loan_chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maths I do not like\n",
    "\n",
    "`scikit-learn` handles most of the math involving Bayesian inference. The math itself is not that hard, but scikit can help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and further reading\n",
    "\n",
    "* [Probabilistic Programming & Bayesian Methods for Hackers](https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/) - Much of this notebook came from their introduction.\n",
    "* [An Intuitive Explanation of Bayes' Theorem](http://www.yudkowsky.net/rational/bayes)\n",
    "* [Think Bayes](http://www.greenteapress.com/thinkbayes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
