{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\r\n",
      "ham\tOk lar... Joking wif u oni...\r\n",
      "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\r\n",
      "ham\tU dun say so early hor... U c already then say...\r\n",
      "ham\tNah I don't think he goes to usf, he lives around here though\r\n",
      "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\r\n",
      "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\r\n",
      "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\r\n",
      "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\r\n",
      "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\r\n"
     ]
    }
   ],
   "source": [
    "!head SMSSpamCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building SciKit-Learn Compatible Transfomers\n",
    "\n",
    "If we use the methods `.fit(self, X, y=None)` and `.transform(self, X)`, we can build transformers that will easily create feature vectors in SciKit-Learn that we can just pop into a Pipeline, and do things more automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at SMS spam data to demonestrate how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sms_data = []\n",
    "sms_results = []\n",
    "\n",
    "with open('SMSSpamCollection') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        sms_data.append(row[1])\n",
    "        sms_results.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'Ok lar... Joking wif u oni...',\n",
       " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'U dun say so early hor... U c already then say...',\n",
       " \"Nah I don't think he goes to usf, he lives around here though\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham', 'ham', 'spam', 'ham', 'ham']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by writing a very dumb featurizer/vectorizer. It will just return a vector [1] for every result.\n",
    "\n",
    "It's a good demonstration of the minimum possible featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DumbFeaturizer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [[1] for _ in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86593682699210339"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe = make_pipeline(DumbFeaturizer(), DecisionTreeClassifier())\n",
    "pipe.fit(sms_data, sms_results)\n",
    "pipe.score(sms_data, sms_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8659368269921034"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_results.count('ham') / len(sms_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline, making a guess of the most common result, gives us ham every time, which is right 87% of the time.\n",
    "\n",
    "We need to make sure our model is better than our baseline.\n",
    "\n",
    "Let's build a better featurizer to try and get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longest_run_of_capital_letters(text):\n",
    "    '''Find the longest run of capital letters and return their length'''\n",
    "    text = re.sub(r'\\W', '', text)\n",
    "    result = re.findall(r'[A-Z]+', text)\n",
    "    if result:\n",
    "        return len(sorted(result, key=len, reverse=True)[0])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = 'My VERY excellent MOTHEr juST servED us NINE PIZZAS'\n",
    "text = re.sub(r'\\W', '', text)\n",
    "result = re.findall(r'[A-Z]+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'VERY', 'MOTHE', 'ST', 'ED', 'NINEPIZZAS']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(result, key=len, reverse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SingleFunctionFeaturizer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        '''All SciKit-learn compatible transformers and classifiers have the same\n",
    "        interface. `fit` should always return the same object (self)'''\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''Given a list of original data, return a list of feature vectors'''\n",
    "        return [[longest_run_of_capital_letters(x)] for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1], [3], [1], [1], [1], [1], [1], [7], [4]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_featurizer = SingleFunctionFeaturizer()\n",
    "sms_featurizer.transform(sms_data[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'Ok lar... Joking wif u oni...',\n",
       " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'U dun say so early hor... U c already then say...',\n",
       " \"Nah I don't think he goes to usf, he lives around here though\",\n",
       " \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\",\n",
       " 'Even my brother is not like to speak with me. They treat me like aids patent.',\n",
       " \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\",\n",
       " 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.',\n",
       " 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91529073941134242"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sms_data, sms_results)\n",
    "\n",
    "pipe = make_pipeline(sms_featurizer, DecisionTreeClassifier())\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FunctionFeaturizer(TransformerMixin):\n",
    "    def __init__(self, *featurizers):\n",
    "        self.featurizers = featurizers\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        '''All SciKit-learn compatible transformers and classifiers have the same\n",
    "        interface. `fit` should always return the same object (self)'''\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''Given a list of original data, return a list of feature vectors'''\n",
    "        feature_vectors = []\n",
    "        for x in X:\n",
    "            feature_vector = [f(x) for f in self.featurizers]\n",
    "            feature_vectors.append(feature_vector)\n",
    "        \n",
    "        return np.array(feature_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.11000000e+02,   1.00000000e+00,   8.10810811e-02],\n",
       "       [  2.90000000e+01,   1.00000000e+00,   2.06896552e-01],\n",
       "       [  1.55000000e+02,   3.00000000e+00,   3.87096774e-02],\n",
       "       [  4.90000000e+01,   1.00000000e+00,   1.22448980e-01],\n",
       "       [  6.10000000e+01,   1.00000000e+00,   3.27868852e-02],\n",
       "       [  1.47000000e+02,   1.00000000e+00,   6.12244898e-02],\n",
       "       [  7.70000000e+01,   1.00000000e+00,   2.59740260e-02],\n",
       "       [  1.60000000e+02,   1.00000000e+00,   3.75000000e-02],\n",
       "       [  1.57000000e+02,   7.00000000e+00,   4.45859873e-02],\n",
       "       [  1.54000000e+02,   4.00000000e+00,   1.29870130e-02]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percentage_of_punctuation(text):\n",
    "    total_length = len(text)\n",
    "    text = re.sub(r'[\\w\\s]', '', text)\n",
    "    punc_length = len(text)\n",
    "    \n",
    "    return punc_length / total_length\n",
    "\n",
    "f = FunctionFeaturizer(len,\n",
    "                       longest_run_of_capital_letters,\n",
    "                       percentage_of_punctuation)\n",
    "f.transform(sms_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94113424264178036"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = FunctionFeaturizer(len,\n",
    "                       longest_run_of_capital_letters,\n",
    "                       percentage_of_punctuation)\n",
    "\n",
    "pipe = make_pipeline(f, DecisionTreeClassifier())\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      0.96      0.97      1252\n",
      "       spam       0.69      0.77      0.73       141\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pipe.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Precision_ is the percentage of instances of the class that are correctly predicted, while _recall_ is the percentage of predictions for that class that are correct.\n",
    "\n",
    "The _f1-score_ is the _harmonic mean_ of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class BagOfWordsFeaturizer(TransformerMixin):\n",
    "    def __init__(self, num_words=None):\n",
    "        self.num_words = num_words\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        words = []\n",
    "        for x in X:\n",
    "            x = TextBlob(x.lower())\n",
    "            words += [word.lemmatize() for word in x.words]\n",
    "        if self.num_words:\n",
    "            words = Counter(words)\n",
    "            self._vocab = [word for word, _ in words.most_common(self.num_words)]\n",
    "        else:\n",
    "            self._vocab = list(set(words))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        vectors = []\n",
    "        for x in X:\n",
    "            x = TextBlob(x.lower())\n",
    "            word_count = Counter(x.words)\n",
    "            vector = [0] * len(self._vocab)\n",
    "            for word, count in word_count.items():\n",
    "                try:\n",
    "                    idx = self._vocab.index(word)\n",
    "                    vector[idx] = count\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            vectors.append(vector)\n",
    "        return vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multiple featurizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_featurizer = make_union(\n",
    "    BagOfWordsFeaturizer(20),\n",
    "    FunctionFeaturizer(len,\n",
    "                       longest_run_of_capital_letters,\n",
    "                       percentage_of_punctuation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to set up textblob:\n",
    "# pip install textblob\n",
    "# python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511844938980617"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(sms_featurizer, DecisionTreeClassifier())\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
