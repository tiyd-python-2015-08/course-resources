{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Classification\n",
    "\n",
    "Linear regression is useful for predicting a lot of different things, especially on a continuum, but it's not always useful if we are essentially calculating a boolean. Finding a category for something (including a boolean) is something Bayesian inference is good at.\n",
    "\n",
    "So we expose our filter to a lot of spam messages and a lot of non-spam messages, and identify which of those are which, and look for features present in each to make a prediction about new data. The more spam/non-spam (aka ham) a filter is exposed to, the better it should get if it's using Bayesian inference.\n",
    "\n",
    "Let's classify a message as spam or ham, and build a belief system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# glob gives us a function called glob that loops over sets of files.\n",
    "# We want to loop over all the training files and give the data to our filter,\n",
    "# and that will involve reading in a bunch of files\n",
    "\n",
    "def read_ling_spam(directory):\n",
    "    files = glob.glob('ling-spam/{}/*.txt'.format(directory))\n",
    "    texts = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            texts.append(f.read())\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ling-spam/nonspam-train/3-380msg4.txt',\n",
       " 'ling-spam/nonspam-train/3-384msg0.txt',\n",
       " 'ling-spam/nonspam-train/3-385msg1.txt',\n",
       " 'ling-spam/nonspam-train/3-385msg2.txt',\n",
       " 'ling-spam/nonspam-train/3-390msg3.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('ling-spam/nonspam-train/*.txt')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_train = read_ling_spam('spam-train')\n",
    "ham_train = read_ling_spam('nonspam-train')\n",
    "spam_test = read_ling_spam('spam-test')\n",
    "ham_test = read_ling_spam('nonspam-test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer takes text and produces a matrix of counts for the words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(spam_train + ham_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the .fit method passes in the data and figures out the \"fit\" for it, which is just\n",
    "# the boolean values for each word\n",
    "\n",
    "X_train = vectorizer.transform(ham_train + spam_train)\n",
    "y_train = ['ham'] * len(ham_train) + ['spam'] * len(spam_train)\n",
    "X_test = vectorizer.transform(ham_test + spam_test)\n",
    "y_test = ['ham'] * len(ham_test) + ['spam'] * len(spam_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = X_train.getrow(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0], dtype=int32),\n",
       " array([  846,  1031,  1648,  1954,  3368,  4912,  5194,  6450,  7119,\n",
       "         7276,  7349,  8248,  8409,  9455, 10903, 12328, 12752, 13076,\n",
       "        13405, 13912, 15527, 15711, 15777, 16379, 16792, 17055, 18708], dtype=int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a5749e3d54af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers, not tuple"
     ]
    }
   ],
   "source": [
    "for col in row.nonzero():\n",
    "    print(vectorizer.get_feature_names()[1,col], X_train[0, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anyone'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'ham',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam',\n",
       " 'spam']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<700x19073 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 110609 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X_train` is a _sparse matrix_, meaning it only stores non-zero values to save on memory/space. If most of the elements of a matrix are expected to be zero, a spare matrix is a good data structure. If most of the elements, the matrix is considered \"dense,\" and a sparse matrix is not a good data structure.\n",
    "\n",
    "`y_train` has a single column, denoting a message as either ham or spam. The indexes match up between `X_train` and `y_train` to link the messages together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['armidale',\n",
       " 'armin',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'arnagardur',\n",
       " 'arnhem',\n",
       " 'arnold',\n",
       " 'aron',\n",
       " 'aronoff',\n",
       " 'around']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_feature_names lets us see what words correspond to which column in the sparse matrix\n",
    "\n",
    "vectorizer.get_feature_names()[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_train+ham_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19073"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multinomial Naive Bayes Classifier does some magic relating our rows and our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99857142857142855"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ooo! Ahh! Holy Bayes!\n",
    "\n",
    "So it's really accurate... for the data we trained it on...\n",
    "\n",
    "We can't judge accuracy based on training data. We need to use our test data, that wasn't part of our fit, to really judge accuracy.\n",
    "\n",
    "Let's check our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97692307692307689"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is making inferences based upon data it hasn't seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# message = ['hi how are you i have a loan for you to consider today my friend is a prince has large sum of money']\n",
    "\n",
    "message = ['i think the natural language processing features of scikit are very useful, and i have had students tell me the same']\n",
    "\n",
    "classifier.predict(vectorizer.transform(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Pipelines make it simple for us to do a lot of transformations on data.\n",
    "\n",
    "With the above example, we had to:\n",
    "* vectorize the source data\n",
    "* transform the vectorized data\n",
    "* fit our MultinomialNB classifier to our data\n",
    "\n",
    "You can create a pipeline to do all that in one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline_map = [('bag_of_words', CountVectorizer()),\n",
    "                #('tfidf', TfidfTransformer()),\n",
    "                ('bayes', MultinomialNB())]\n",
    "\n",
    "# def pipeline(x, y):\n",
    "#     return MultinomialNB(TfidfTransformer(CountVectorizer(x), y))\n",
    "del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(pipeline_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bag_of_words', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to get this data into our pipeline\n",
    "pipeline.fit(ham_train + spam_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass our test data into the pipeline and see what we would predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pipeline.predict(ham_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(res).count('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97692307692307689"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(ham_test + spam_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "* [Ling-Spam dataset](http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex6/ex6.html)\n",
    "  * Preprocessed\n",
    "* [Bag of Words](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "  * CountVectorizer\n",
    "    * binary=True\n",
    "* [Multinomial vs Bernoulli Naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "* [20 Newsgroups](http://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
